---
title: Logistic Regression Practice 1
date: 2021-04-18 14:00:00
categories:
  - Machine Learning
tags:
  - machine-learning
  - ml
  - knn
  - regression
  - kaggle
  - competition
typora-root-url: ../
---



## [ML] LR을 활용한 분류 문제 (1)

> Week#6 / Reference: Prof.Choi / based on Colab, Kaggle



### Overview

#### 은하계 분류

> 본 데이터 셋은 관측 후 형태에 따라 분류된 은하계로 구성되어 있으며, 세종대학교 최유경 교수님의 [은하계 분류](https://www.kaggle.com/c/2021-ml-p4) kaggle competition를 출처로 둔다.

#### Description

다음과 같이 3가지 종류의 은하 데이터 셋이 제공된다.

- **Spiral** - 일반적으로 알려진 나선 형태의 은하
- **Edge** - 은하는 나선 은하지만 관측 방향에 의해 뾰족한 형태를 띄는 은하
- **Smooth** - 은하는 은하 디스크의 두께가 얇지 않고 두껍게 보이는 은하

편의를 위해 각 은하계 사진은 1D Feature 로 가공되어 제공된다. 2D 영상을 1D로 표현하기 위한 방법은 다음과 같다.

> 각 사진은 ImageNet으로 pretrain된 VGG16을 활용하여 1-Dim 의 벡터로 제공된다. 이 벡터는 종단 두 개의 FC Layer를 통해 나온 4,096 차원의 벡터에 PCA를 사용해 64차원으로 가공되어 제공된다.

학습 데이터는 총 6,000개, 평가 데이터는 총 1,500개이며 학습데이터에 해당되는 분류 정보도 포함한다.



### Preparation

- kaggle install

  ~~~python
  !pip uninstall -y kaggle
  !pip install --upgrade pip
  !pip install kaggle==1.5.6
  ~~~

- API token upload

  ~~~python
  !mkdir -p ~/.kaggle
  !cp kaggle.json ~/.kaggle/
  !chmod 600 ~/.kaggle/kaggle.json
  ~~~

- Import libraries

  ~~~python
  import numpy as np
  import pandas as pd
  ~~~


### Data Loading

Competition의 Data 탭에서 필요한 데이터를 가져온다.

- Import dataset from Kaggle

  ~~~python
  !kaggle competitions download -c 2021-ml-p4
  !unzip 2021-ml-p4.zip
  ~~~

- Input data

  ~~~python
  tdp = pd.read_csv('train_desc_pca.csv')
  tl = pd.read_csv('train_label.csv')
  test = pd.read_csv('test_desc_pca.csv')
  
  X = tdp # label을 제외한 features 정보 X에 저장
  y = tl.drop('Id', axis=1) # 'Id' column drop 후 label값만 저장
  ~~~
  


### Data Preprocessing

- Normalization

  ~~~python
  from sklearn.preprocessing import MinMaxScaler # 정규화 method import
  msc = MinMaxScaler()
  
  X_sc = msc.fit_transform(X,y) # X를 fit할 때 y도 함께 넣어줌으로써 경향성 조절
  test_sc = msc.transform(test) # test는 (X,y)의 경향에 맞춘다
  ~~~
  
- Data framing

  ~~~python
X_sc = pd.DataFrame(X_sc,columns=X.columns)
  test_sc = pd.DataFrame(test_sc,columns=test.columns)
  ~~~
  
- Fitting / Scoring

  > Logistic regression의 함수 parameter 조절을 통해 다양한 규제강도에 따른 실험을 할 수 있다.

  - L₁, L₂ 규제화
  - C = 1/𝜆 를 통한 규제화
  - Test data의 label을 알 수 없을 경우, train data 일부를 validation data로 구성하여 test

  규제강도가 클수록 추정된 계수들의 절대값이 작아진다. L₁ 규제화의 경우 규제 강도가 클수록 "Sparce", 계수에 0이 많아진다.  즉, 계수에 대응하는 특성변수를 제거하는 역할을 담당한다고 볼 수 있다. 본 코드에서는 C 값을 조절하며 정확도를 향상시켜 보았다.

  ~~~python
  from sklearn.linear_model import LogisticRegression
  clf = LogisticRegression(random_state=1, C=1.6, max_iter=300)
  clf.fit(X_sc, y) # 학습 적용
  
  result = clf.predict(test_sc) # 예측 적용
  ~~~

- Submission

  ~~~python
submit = pd.read_csv('sample_submit.csv')
  submit['Category'] = result
  ~~~
  
~~~python
  submit.to_csv('submit.csv',index=False)
  ~~~
  
~~~python
  !kaggle competitions submit -c 2021-ml-p4 -f submit.csv -m "minmax, fit X, C=1.6, maxiter=300, solver=saga"
  ~~~
  
  




### Result

<img src="/images/post15-ml-w5-3/3.png" alt="score" style="zoom:40%;border:none" /> 

MAE에 따라 1283.53995 정도로 평가되었다. Leaderboard 상에서는 86명 중 13th position정도이다. 아쉽게 deadline 이후에 더 좋은 점수가 나와서 public score에는 반영되지 않았다. :sob: